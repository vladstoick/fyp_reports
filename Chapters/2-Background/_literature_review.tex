\section{Literature review}

The topic of assessing SQL has been looked into by various scholars. While most existing work focuses on the learning and teaching aspect, there is one more recent work done by \cite{literature:xdata} which also talks about automated grading.

All existing work acknowledges that there are many issues with students learning SQL \citep{literature:assesql, literature:sqlify}. While many students are able to express queries in natural language, they have issues expressing them in SQL \citep{literature:mitrovic}. While teaching a university course about SQL, \cite{literature:mitrovic} noticed that many students also struggle with memorizing the database schema, often making naming mistakes. Furthermore, many students struggled to understand what mistakes they were making because they could only see detailed compilation errors \citep{literature:mitrovic}. These difficulties have been found by multiple scholars \citep{literature:assesql, literature:sqlify, literature:kearns, literature:mitrovic}.

The obstacles of learning SQL can be associated with the way SQL can be learned. Constructing correct queries is not a skill that can simply be learned without significant effort and sufficient practice \citep{literature:assesql}. An inexperienced student will also have trouble visualizing the results of a query \citep{literature:assesql}.

\subsection{Tutor applications} \label{ch:lit:sec:tutor}

Due to the nature of existing work, most past work has tried to improve learning SQL by introducing a \textit{smart} tutor that can guide students when they make mistakes. Throughout the existing literature, there have been many attempts at creating such applications:

\begin{itemize}
    \item AsseSQL \citep{literature:assesql}
    \item SQL-Tutor \citep{literature:kearns}
    \item SQLAtor \citep{literature:sqlator}
    \item ActiveSQL \citep{literature:activesql}
    \item SQLify \citep{literature:sqlify}
\end{itemize}

All tutor applications listed above are meant to aid the student in their learning process. There are multiple ways the tutoring application can improve the teaching experience. In the applications listed above we noticed the following features:

\begin{itemize}
    \item Displaying the database schema
    \item Providing feedback to students (in practice mode). The level of feedback varies from tool to tool. Some tools simply opt for displaying if the query is correct or wrong, while others provide a more detailed view of the results \citep{literature:assesql, literature:activesql}.
    \item Automated grading using one of the following algorithms:
        \begin{itemize}
            \item Based on percentage of matched results: in some cases the grade was binary: that is either 100\% or 0\% \citep{literature:assesql}, while in other cases a grade was given based on how many results are matched \citep{literature:activesql}.
            \item Based on peer review who assigns certain levels that a query meets \citep{literature:sqlify} in three factors: the output schema, the syntax of the query, and query semantics
        \end{itemize}
    \item Support for typing queries in relational algebra
\end{itemize}

Using these applications in the teaching process has been correlated to increased confidence in using SQL \citep{literature:activesql} and better performance in examinations \citep{literature:sqlify}. In addition, one quantitative study done with students who used such applications \citep{literature:activesql} showed that this type of tutor (especially as a web application) is helpful to students, with 92\% of them saying that using the application increased their understanding of SQL. Furthermore, 85\% said that practicing SQL online suits them better than testing their ability using paper tests.

As previously mentioned, all these tools provide some sort of feedback, and all rely on displaying the result of the query and indicating which rows are not correct. These sort of hints can help the students understand what is wrong with their query. However, these sort of hints do not provide any helpful insights on the actual query: for example, they do not indicate if a \mintinline{mysql}{WHERE} condition is wrong, or if a \mintinline{mysql}{DISTINCT} filter is wrong.

While most applications described above do a good job at helping students learn SQL, their grading algorithms have multiple flaws. When grading based on matched results, one of the common issue encountered is that students end up with a query that is incorrect but it returns the correct results \citep{literature:assesql}. In addition, the lack of partial marking for some tools means that a query very far away from being correct will receive the same grade as a query that is only slightly incorrect \citep{literature:assesql}.

In the cases where partial marking exists, it is done based on the percentage of matched results. However, this approach has clear flaws as identified by the later work done by \cite{literature:xdata}. \cite{literature:xdata} identifies two main problems with this approach:

\begin{itemize}
    \item Students who make simple mistakes such as using $>$ instead of $<$ will most likely lose all marks even if the terms compared are correct
    \item When the expected query is supposed to return no results, a clearly wrong query such as $1 = 2$ will return no results as well.
\end{itemize}

In addition, we found that the results also heavily depend on the data set on which the two queries are compared. A wrongly defined data set could lead to correct results even if the student's query is different. For instance, if we look at the following case: a table that has one columns. The data set included is (1, 2, 5, 7). The solution is looking for all rows that have a value less than 5. That means that a query such as \mintinline{mysql}{SELECT * from table1 WHERE column < 7} will return the expected results.

\subsection{XData}

More recent contributions by \cite{literature:xdata} improve the issues with existing learning tools. \cite{literature:xdata} have built XData, \textit{an interactive platform} for grading and learning SQL. Their work identifies all existing issues with SQL tools that we described above with regards to grading SQL.

The main focus of XData is to improve the partial grading of queries. XData uses a different approach to assessing SQL compared to the tutor tools. Instead of considering the query results as the main aspect of an exercise, they consider the query components as the focus point when grading a query.

\subsubsection{Components of a \mintinline{mysql}{SELECT} SQL query}

A \mintinline{mysql}{SELECT} query is made out of multiple components. The official  \cite{mysql:documentation} \footnote{At the time
of writing this document, version 5.7 is the most recent version available} provides the following general syntax for a \mintinline{mysql}{SELECT}:
\footnote{Some elements from the full syntax have been removed, as they
were not relevant for this project. For instance, file output is not relevant here so it
was removed.}

\begin{minted}{mysql}
SELECT
  [ALL | DISTINCT | DISTINCTROW ] select_expr
  [FROM table_references]
  [WHERE where_condition]
  [GROUP BY [col_name | expr | position] [ASC | DESC], ...]
  [HAVING where_condition]
  [ORDER BY [col_name | expr | position] [ASC | DESC], ...]
  [LIMIT [[offset,] row_count | row_count OFFSET offset]]
\end{minted}

From this we can get the following components:

\begin{enumerate}
  \item \textbf{Uniqueness filtering}: what type of filtering should be applied. There are
  three main options here: \mintinline{sql}{ALL} (the default option),
  \mintinline{sql}{DISTINCT}, and \mintinline{mysql}{DISTINCTROW}
  \item \textbf{\mintinline{mysql}{SELECT} clause}: the list of projected attributes. MySQL
  also accepts a nested sub-query as an attribute.
  \item \textbf{\mintinline{mysql}{FROM} clause}: the list of tables used
  \item \textbf{\mintinline{mysql}{WHERE} clause}: the list of conditions for selecting rows
  \item \textbf{\mintinline{mysql}{GROUP} clause}: the list of attributes on which grouping will be
  done
  \item \textbf{\mintinline{mysql}{HAVING} clause}: the list of filter conditions for aggregate
  attributes
  \item \textbf{\mintinline{mysql}{ORDER BY} clause}: how ordering of rows should be done
  \item \textbf{\mintinline{mysql}{LIMIT} and \mintinline{mysql}{OFFSET} clauses}
\end{enumerate}

\subsubsection{Problems with comparing components of a query}

In SQL there are often many ways to write the same query.
For instance, the following pairs will return the same results and they are
just as correct.

\begin{itemize}
  \item \mintinline{mysql}{SELECT A.b FROM t1 as A;}

  \mintinline{mysql}{SELECT b FROM table;}
  \item \mintinline{mysql}{SELECT t1.id FROM t1 JOIN t2 on t1.id = t2.id;}

  \mintinline{mysql}{SELECT t2.id FROM t1 JOIN t2 on t1.id = t2.id;}
  \item \mintinline{mysql}{SELECT a from t1 where a.id > 1;}

  \mintinline{mysql}{SELECT a from a.id >= 2;}
\end{itemize}

Therefore, we can see that a simple comparison of elements will not be efficient in spotting if two queries are actually different. Therefore, before we can compare the two queries, we need a way to transform the two queries to a similar form. Without those transformations, the simple comparison may indicate
that two queries are very different.

\subsubsection{Canonicalization of queries} \label{ch:lit:sec:canonicalization}

To overcome the issues described above, \cite{literature:xdata} perform a transformation step before comparing the components of two queries. This canonicalization step has the purpose of removing \textit{any irrelevant syntactic variation} \citep{literature:xdata}. In orer to do that, XData applies multiple transformations to a query:

\begin{itemize}
    \item \textbf{Attribute disambiguation}: Unqualified columns are column names whose interpretation depends on the current context \citep{mysql:documentation}. For example, the column identifier \mintinline{mysql}{id} can represent two or more different actual columns depending on the context. To avoid this uncertainty, all columns must be transformed to qualified columns.
    \item \textbf{Removing \mintinline{mysql}{BETWEEN}}: a \mintinline{mysql}{BETWEEN} can be transformed to two separate \mintinline{mysql}{<=} and \mintinline{mysql}{>=}. This will ensure that a query written with a \mintinline{mysql}{BETWEEN} will be matched with a query written with a \mintinline{mysql}{<} and a \mintinline{mysql}{>}.
    \item \textbf{Transforming \mintinline{mysql}{NOT}}: Another transformation used is transforming \mintinline{mysql}{NOT} conditions by removing the \mintinline{mysql}{NOT} and changing the condition to the opposite one. For instance: \mintinline{mysql}{NOT a > 1} is the same condition as \mintinline{mysql}{a <= 1}.
    \item \textbf{Transform \mintinline{mysql}{>} and \mintinline{mysql}{>=} to \mintinline{mysql}{<} and \mintinline{mysql}{<=}}
    \item \textbf{Transforming equivalent columns}: When looking at queries that include one or more tables, it is often the case that a column reference is equivalent across tables - which is always the case for foreign keys. For instance, in a query with the following table expression: \begin{minted}{mysql}
    FROM table1
    LEFT JOIN table2 on table1.id = table2.fid
    LEFT JOIN table3 on table2.fid = table3.random_id
    \end{minted}
    the following columns are equivalent: \mintinline{mysql}{table1.id}, \mintinline{mysql}{table2.fid}, \mintinline{mysql}{table3.random_id}, meaning that using any of them in a query would have the same result.
\end{itemize}

\subsubsection{Limitations of canonicalization} \label{ch:lit:sec:can:subsec:limit}

All these transformations have the purpose of making the two queries as comparable as possible. However, the authors acknowledge that there are certain limitations with this approach.

One important issue is related to sub-queries with \cite{literature:xdata} acknowledging that further work on sub-queries is crucial. When looking at the source code of XData \footnote{Available at https://gitlab.com/xdata/xdata-web. No LICENSE is provided}, we can see that the way the way the comparison is done is by trying to recursively match sub-queries with another sub-query. While this approach should generally work, there are cases when this will fail to assign any partial grades if the student uses a sub-query when there would be an alternative solution without a sub-query. Another issue identified by \cite{literature:xdata} is related to the use of \mintinline{mysql}{DISTINCT} in a sub-query in \mintinline{mysql}{FROM}, compared to using \mintinline{mysql}{DISTINCT} in the outer \mintinline{mysql}{SELECT}.

\subsubsection{Partial grading}

As mentioned before, XData assigns a grade by comparing the components. Each component is assigned a predefined weight (either given by the teacher, or defined as $1 / total_{components}$) which is used to calculate the final grade. Each query component is composed of multiple sub-parts. The algorithm of XData will try to match sub-parts. (including position, where relevant) and then penalize missing or additional sub-parts (a minimum grade of 0 is used for each component). Sub-queries are recursively graded and then matched with sub-queries from other queries (if any exist). In the case of Boolean expressions (\mintinline{mysql}{WHERE} and \mintinline{mysql}{HAVING}), the grading algorithm does not care about the Boolean operator used, and only cares about conditions.

\subsection{Conclusion of literature review}

All the tools mentioned previously have been deployed and used, according to the authors, successfully to grade student assignments, including the tutor applications. Later work by \cite{literature:xdata} showed that the approaches used by the available commercial applications described in section \ref{ch:lit:sec:tutor} have multiple flaws. Due to these flaws, such grading algorithms work better only in a \textit{tutor} application, rather than a grading application. In such a learning environment, the end goal of the student is to build a 100\% correct query, since he is able to attempt solving the query multiple times. On the other hand, in an assessment scenario, a student is more likely to make mistakes given the fact that he does not know if the query he wrote is correct. As mentioned before, grading on matched results (the approach used by all \textit{tutor} applications) is not necessarily relevant.

On the other hand, work done by \cite{literature:xdata} with XData is better suited for grading assessments. XData's approach of canonicalizing queries and comparing components should yield grades that reflect the student's effective ability to construct queries.

