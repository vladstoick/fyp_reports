\chapter{Implementation and testing}

\section{Library: connecting to a MySQL server and executing queries} \label{ch:impllib:sec:connecting}
To connect to a MySQL server, the application uses the Ruby library mysql2. The library, or gem as it's called in Ruby, provides the implementation for connecting, querying and retrieving results from a MySQL server. mysql2 is a binding to MySQL's C library libmysql. mysql2 is the more modern and lean version of the mysql version. Compared to mysql gem, mysql2 gem can be 2 times faster and is built with Ruby in mind. Furthermore, mysql2 is also much more popular with over 42 million downloads on RubyGems, compared to mysql's 8 million downloads.

To connect to a MySQL server, the library requires the address and port of the server, and an account and password. The account must be the root user or at least one that has the permission to create and drop databases, to create and drop users, and to grant permissions to an user.

\subsection{Handling concurrent submissions}

As the library will be used in a web application, concurrency is inevitable. Users can submit solutions at any time and it is possible that two users submit solutions at the same time. Obviously, concurrency can be ignored by limiting the execution of only one compile or assessment at a time. However, this solution can lead to frustrating waiting times and requires the implementation of background workers to compile the work. Therefore, the tool opted to implement a solution that allows concurrent executions.

To allow concurrency, each submission or compilation is performed using different connections to different databases (a MySQL server can have multiple databases).  Every compilation or submission begins by creating a new and unique database based on the current time. The database name will follow the format \texttt{HOURMINUTESECOND}. While this should cover most cases, due to the concurrent nature of the application, it might be the case that two connections try to create a database with the same name. However, MySQL statements are atomic. That means that two statements can not both change the schema of the MySQL server. Therefore, it is guaranteed that at least one create will fail. In this case, we repeat all failed creations (by using the new time) until they succeed. On second and further attempts, we also add a \mintinline{ruby}{_attempt} at the end of the database name to reduce the chance of another conflict. At the end of the compilation, the newly created database will be dropped and all data associated discarded.

%TC:ignore
\begin{code}
    \begin{minted}{ruby}
success = false
attempt = 0
while !success do
  time = DateTime.now

  if attempt > 0
    @database = "#{Time.now.strftime("%H%M%S")}_#{attempt}"
  else
    @database = "#{Time.now.strftime("%H%M%S")}"
  end

  begin
    @client.query("CREATE DATABASE `#{@database}`")
    success = true
  rescue Mysql2::Error => exception
    raise exception unless exception.message.include?("database exists")
    success = false
    attempt += 1
  end
end
\end{minted}
    \caption{Creating a new database for each run}
    \label{fig:creating_new_database}
\end{code}
%TC:endignore

\subsection{Preventing malicious actions from input SQL queries}

Considering the fact that the library executes arbitrary queries, the risks associated with malicious SQL are significant. The application never returns back the query results which means that the potential for data leaking through this does not exist. However, an arbitrary query can destroy or modify other databases on the MySQL server. Therefore, the library must take extra precautions as it deals with unchecked user code. To prevent malicious actions, we create a new MySQL user that only has permission for the newly created database.

%TC:ignore
\begin{code}
\begin{minted}{ruby}
@client.query("CREATE USER IF NOT EXISTS `#{@database}`;")
@client.query("GRANT ALL PRIVILEGES ON `#{@database}`.* TO `#{@database}` WITH GRANT OPTION;")
\end{minted}
\caption{Creating a new user with permissions for the new database}
\label{fig:creating_new_user}
\end{code}
%TC:endignore
All used queries are performed using this user, instead of using the root one. The temporary user is also deleted at the end of the compile/ assessment execution. This way, the user input can only damage the created database for his assessment. However, this is not an issue considering these are short-lived databases which are destroyed at the end of the assessment.

The only way to get around the limitation of the restricted user would be to use a different user. Changing the user in MySQL is not possible through a MySQL command. The only possible way would be to use the \texttt{system} command which executes bash code in combination with the \texttt{mysql -uroot --password} bash command if they knew the root password, but not the url of the database. However, the \texttt{system} command is only available on connections opened with the \texttt{mysql} bash command, which is not the case for \texttt{mysql2} - so users can not exploit this method. Furthermore, the user has limited permissions so he can not run commands such as \mintinline{mysql}{SET PASSWORD} to change existing users.

\section{Library: parsing and transforming queries}

Part of the canonicalization and grading process, SQL queries will go through multiple transformations after being parsed and separated in independent components. MySQL does not provide an official parser for any programming language, so the library had to use a 3rd party tool. The advantage of using an existing parser is that we can ignore the implementation details of parsing.

The library initially used the Ruby gem sql-parser. Throughout the development process, there have been multiple problems associated with this tool. Most importantly, the library did not have support for multiple SQL statements that we required. Unfortunately, many issues with sql-parser were discovered only late in the project.

An alternative was represented by pg\_query Ruby gem. Internally it uses PostgreSQL's parsing library libpg\_query built in C++. pg\_query provides much better code and stability, due to its nature of being part of a production database system, compared to sql-parser which was only used for parsing. PostgreSQL, like MySQL, is a database system that is widely used, being the 4th most used database engine according to \cite{db_engine:statistics}. Although both PostgreSQL and MySQL have SQL at their core, each one implements their own version of SQL. Therefore, a query might work in MySQL, but not work in PostgreSQL, or return different results. For instance, in MySQL string comparison is case insensitive, while PostgreSQL is not. In addition, each SQL version adds their own functions that diverge from Standard SQL. Therefore, implementing pg\_query turned out to be impossible due to the many differences in syntax between them. In addition, time constraints made it unjustifiable to spend time on re-implementing all transformers already built.

\subsection{Extending sql-parser}

In the end, due to the issues described previously, a decision was made to continue using sql-parser. Fortunately, sql-parser uses a MIT license which allowed us to fork the library and implement the fixes in the fork. The parser was implemented using Racc's grammar files. According to the GitHub page of the tool, Racc is a \textit{LALR(1) parser generator} that generates Ruby code. LALR parsers are also known as "Look Ahead Left to Right" parsers. The fork created implemented the following functionality:
\begin{itemize}
    \item Support for \mintinline{mysql}{DISTINCT}, \mintinline{mysql}{DISTINCTROW}, \mintinline{mysql}{ALL} in \mintinline{mysql}{SELECT} statements
    \item Support for \mintinline{mysql}{LIMIT} and \mintinline{mysql}{OFFSET}
    \item Support for using a qualified column in \mintinline{mysql}{ORDER BY} clause
    \item Support for using the columns number in \mintinline{mysql}{GROUP} clause
    \item Support for using subqueries in \mintinline{mysql}{FROM} clause
\end{itemize}

The process of adding a new feature was formed of multiple parts:
\begin{enumerate}
    \item Create a \mintinline{ruby}{Node} class representing the new clause, if a new clause was implemented. A \mintinline{ruby}{Node} represents an element of a query: a clause, a number, a word, a condition, etc. For instance, the newly created \texttt{LIMIT} node has the following structure:
    \begin{code}\centering
\begin{minted}{ruby}
class LimitClause < Node
    def initialize(limit, offset)
        @limit = limit
        @offset = offset
    end

    attr_reader :limit, :offset
end
\end{minted}
\caption{Limit clause \mintinline{ruby}{Node}}
\label{fig:limit_clause}
\end{code}
    \item Update existing \mintinline{ruby}{Node} to link to the newly created node. For instance, the \mintinline{ruby}{LimitClause} node had to be linked to the \mintinline{ruby}{TableExpression} node.
    \item Add the new parsing rules to Racc grammar file. For instance, when adding the LIMIT clause there are three options: there is only a limit number, there are two numbers for limit and offset separated by the word \texttt{OFFSET}, or the two numbers are separated by a comma:
\begin{code}
    \centering
    \begin{minted}{ruby}
  limit_clause
: # no action
| LIMIT unsigned_integer { result = SQLParser::Statement::LimitClause.new(val[1], nil) }
| LIMIT unsigned_integer OFFSET unsigned_integer { result = SQLParser::Statement::LimitClause.new(val[1], val[3]) }
| LIMIT unsigned_integer comma unsigned_integer { result = SQLParser::Statement::LimitClause.new(val[3], val[1]) }
    \end{minted}
    \caption{Limit clause \texttt{Racc}}
    \label{fig:limit_clause_racc}
\end{code}
\end{enumerate}

\subsection{Using sql-parser to parse SQL queries}
Using sql-parser to parse SQL queries is straight forward. The library provides the \mintinline{mysql}{scan_str} which transform a string (the SQL query) into a SQL Abstract Syntax Tree (AST). The AST is formed of multiple nodes. As previously mentioned in the lat section, a node is a component of the clause. The general structure of the AST for a SELECT query has the following structure is represented in figure \ref{fig:select_ast}.

\begin{figure}[ht]
\centering
\begin{tikzpicture}[sibling distance=8em,
  every node/.style = {shape=rectangle, rounded corners,
    draw, align=center,
    top color=white, bottom color=blue!20}]]
  \node { \ttfamily Select }
    child { node {\ttfamily SelectList} }
    child { node {\ttfamily TableExpression}
        child { node {\ttfamily FromClause } }
        child { node {\ttfamily WhereClause } }
        child { node {\ttfamily GroupByClause } }
        child { node {\ttfamily HavingClause } }
        child { node {\ttfamily LimitClause } } }
    child { node {\ttfamily Filter} };
\end{tikzpicture}
\caption{General structure of the SELECT's AST}
\label{fig:select_ast}
\end{figure}
All the leaves presented in figure \ref{fig:select_ast} also have their nodes. For instance, SelectList has an array of columns which can be of many types (QualifiedColumn, Column, AggregateColumn). In addition, what we previously called Boolean components (WHERE and HAVING) have both subtrees representing the Boolean expression.


\subsection{Using sql-parser to change queries}
sql-parser also provides a way to change a parsed query (which is now a combination of multiple Nodes) back to a SQL query. Unfortunately, the process of internally modifying the structure of a query is not well-defined and there is no public interface exposed. Each node has one or more private instance variable that represent the values of the Node. For instance, the limit node shown in listing \ref{fig:limit_clause}, has two such variables: limit and offset. sql-parser does not provide a way to change these properties as all Nodes just expose a reader method (set using \mintinline{ruby}{attr_reader}). Fortunately, ruby provides a \mintinline{ruby}{instance_variable_set} method while allows anyone with a reference to an object to change that object's internal variables even if they are private and no setter is exposed. It is worth mentioning that while this approach might work, the use of this method \mintinline{ruby}{instance_variable_set} goes against the principle of encapsulation, and might mean that a future update to the library can lead to errors, if the internal structure of Nodes is modified.

\begin{code}
\begin{minted}{ruby}
@parsed_query.query_expression.list.instance_variable_set(
  "@columns",
  new_columns
)
\end{minted}
\caption{Example of updating the column list for a parsed query}
\end{code}

After a query is modified, sql-parser exposes a \mintinline{ruby}{.to_sql} method on each Node that can be used to transform a Node to a SQL statement.

\section{Library: handling sub-queries}

Unfortunately, compared to XData, the library can not handle submissions with XData. Some work to implement this has been attempted and is available in the current code: canonicalization of sub-queries, comparison of nested queries, updating sql-parser to support sub-queries in the FROM clause, etc. Unfortunately, this work has been added very late in the project which meant that most existing work had to be redone. The work had to be redone because some parts of the library made the assumption that no sub-queries are present. For instance, the library contains multiple canonicalizations that make use of nested sub-queries. 

If the library will encounter a sub-query, it will return an error explaining that such SQL queries are not currently supported.

\section{Library: canonicalizing queries}

As previously mentioned in section \ref{ch:lit:sec:improved_canon}, the library will implement a canonicalization step. The library implements all canonicalizations done by XData and described in section \ref{ch:lit:sec:canonicalization}, and the additional ones presented in section \ref{ch:lit:sec:improved_canon}. All transformations use sql-parser's transformations ability combined with the ability to make queries on the database.

As mentioned in the design section \ref{ch:lit:sec:improved_canon}, the canonicalization process is done sequentially in a specific order that ensures that later canonicalizations do not make changes that make changes incompatible with previously executed transformations. 

\begin{code}
\begin{minted}{ruby}
def transform(query)
  TRANSFORMERS.each do |transformer_class|
    query = transformer_class.new(@connection).transform(query)
  end

  query
end
\end{minted}
\caption{Sequential transformation of a query}
\label{fig:sequential transformation of a query}
\end{code}

\subsection{Transforming \mintinline{mysql}{*} to all columns}
To transform \mintinline{mysql}{*} to MySQL, the library uses the fact that it doesn't need to support sub-queries. That means that it can simply look at what tables are selected and then perform \mintinline{mysql}{SHOW COLUMNS FROM table_name} on each table to get the full list of columns for each table. The library will then simply update the list of columns (initially represented by a \mintinline{mysql}{*}) to the new list of columns which contain the full list of \texttt{table\_name.column} for each selected table.

\begin{code}
\begin{minted}{ruby}
new_columns = table_list.map do |table|
  columns_query = "SHOW COLUMNS from #{table}"
  columns = @connection.query(columns_query).map { |k| k["Field"] }

  columns.map do |column_name|
    SQLParser::Statement::QualifiedColumn.new(
      SQLParser::Statement::Table.new(table),
      SQLParser::Statement::Column.new(column_name)
    )
  end
end.flatten
\end{minted}
\caption{Getting the full list of columns for a query}
\end{code}

\subsection{Transforming ambigous columns to unambigous columns}
Transforming ambiguous columns to unambiguous columns is done in a similar way as the previous transformations. The transformation makes use of two important aspects:
\begin{enumerate}
    \item One can determine the full list of columns for each table expression component, by running \mintinline{mysql}{SHOW COLUMNS FROM table_name}.
    \item An ambiguous column can belong to a single table from a query. If a column cannot be made qualified, then MySQL will automatically return the \textit{column xx in field list is ambiguous''} error.
\end{enumerate}

Therefore to transform an ambiguous column we must go through the full list of columns of each table until we find a match. We then transform the ambiguous column to a qualified column. This process can be seen in listing \ref{fig:find_table}.

An additional type of ambiguous column type is the position reference one which is found in the GROUP and ORDER clauses. In these two clauses, one can write \mintinline{mysql}{ORDER BY 2} where 2 references the second column from the select list. To find the qualified column that the position column references we need to look at the select list (after it was transformed to qualified columns) and select the right position: \mintinline{ruby}{@parsed_query.query_expression.list.columns[column.value - 1]} (position columns start at index 1, while arrays start at 0 in ruby).

Finally, the library also considers the aggregate column types which inside might contain a ambiguous column as well. Aggregate columns are of type \mintinline{ruby}{SQLParser::Statement::Aggregate} which has an attribute of type column. Therefore, we need to apply the same transformation to the inner column attribute.

In sql-parser, unqualified columns have the parsed node type \mintinline{ruby}{SQLParser::Statement::Column}, while qualified columns have the parsed node type \mintinline{ruby}{SQLParser::Statement::QualifiedColumn}.

%TC:ignore
\begin{code}
\begin{minted}{ruby}
def find_table_for(column_name)
  table_list.detect do |table|
    columns_query = "SHOW COLUMNS from #{table}"
    columns = @connection.query(columns_query).map { |k| k["Field"] }
    columns.include?(column_name)
  end
end
\end{minted}
\caption{Determining the table for an ambigous column with name}
\label{fig:find_table}
\end{code}
%TC:endignore


\subsection{Transforming equivalent columns}

The transformation of equivalent columns is a two step process. First, the library determines which components are equivalent, and after that it updates all column references to the minimum lexicographically string from the equivalence group.

To determine the equivalent columns the library builds a undirected graph $G(V, E)$:
\begin{enumerate}
    \item $V$: the list of all columns used in the table expression
    \item $E$: there is an edge between $v_1$ and $v_2$ if and only if in the table expression there is a join condition based on the equality of $v_1$ and $v_2$. To build the edges, the library goes over all join conditions from the SQL statement and builds the edges as described above.
\end{enumerate}

We can then apply a strongly connected component (SCC) algorithm to obtain all SCCs from a graph. If a column $v$ belong to component $c$, then it means that $v$ is equivalent to all other $v_e$, where $v_e \in c$.

\begin{figure}[H]
\begin{tabular}{ c c }
\begin{minipage}[t]{0.5\textwidth}
\begin{minted}{mysql}
SELECT *
FROM table1
LEFT JOIN table2 on table1.id = table2.fid
LEFT JOIN table3 on table2.fid = table3.random_id
\end{minted}
\end{minipage}
&
\raisebox{-.5\height}{\includegraphics[height=4cm]{Chapters/5-Implementation/scc.png}}
\end{tabular}
\caption{Example of equivalence graph}
\end{figure}

To build the graph we use a Ruby library called RGL. RGL provides the implementation of various graph structures and graph algorithms (including the SCC algorithm).

\begin{code}
\begin{minted}{ruby}
equivalence = equivalences_list.detect do |equivalences|
  equivalences.include?(column.to_sql)
end

if equivalence.present?
  # transform qualified columns in sql form to two strings representing the
  # table and the column name
  table_name, column_name = equivalence.sort.first.remove("`").split(".")

  SQLParser::Statement::QualifiedColumn.new(
    SQLParser::Statement::Table.new(table_name),
    SQLParser::Statement::Column.new(column_name)
  )
else
  column
end
\end{minted}
\caption{Transforming equivalent columns}
\end{code}

\subsection{Transforming conditions from WHERE, HAVING, and JOIN contiions}
The WHERE and HAVING clauses and the JOIN conditions are represented by a Boolean expression tree. When transforming these clauses it is essential to ensure that the structure of the expression is not altered - that is the before and after expressions are equivalent. To do this, the algorithm traverses the tree recursively and only replaces leafs with either another leaf (in the case of transforming a condition to another) or to a inner node that has two leaves (in the case of transforming a condition to multiple another).

\begin{code}
\begin{minted}{ruby}
def transform_between_queries(statement)
  if statement.is_a?(SQLParser::Statement::SearchCondition)
    statement.class.new(
      transform_between_queries(statement.left),
      transform_between_queries(statement.right)
    )
  elsif statement.is_a?(SQLParser::Statement::Between)
    transform_between_query(statement)
  else
    statement
  end
end
\end{minted}
\caption{Example of traversing a Boolean expression tree}
\end{code}

\subsubsection{Transforming \mintinline{mysql}{BETWEEN} predicate}

A \mintinline{mysql}{column BETWEEN a AND B} predicate will be transformed to two separate predicates: \mintinline{mysql}{column >= a} and \mintinline{mysql}{column <= b}. 

\begin{code}
\begin{minted}{ruby}
def transform_between_query(predicate)
  SQLParser::Statement::And.new(
    SQLParser::Statement::GreaterOrEquals.new(predicate.left, predicate.min),
    SQLParser::Statement::LessOrEquals.new(predicate.left, predicate.max)
  )
end
\end{minted}
\caption{Transforming a BETWEEN predicate}
\label{fig:transforming_a_betweeb}
\end{code}

\subsubsection{Transforming \mintinline{mysql}{NOT} comparison predicates}

In the case of \mintinline{mysql}{NOT} predicates, the transformation process simply transforms the predicate to its opposite:
\begin{enumerate}
    \item \mintinline{mysql}{>} becomes \mintinline{mysql}{<=}
    \item \mintinline{mysql}{>=} becomes \mintinline{mysql}{<}
    \item \mintinline{mysql}{<} becomes \mintinline{mysql}{>=}
    \item \mintinline{mysql}{>=} becomes \mintinline{mysql}{>}
\end{enumerate}

In addition to these 4 predicate types, NOT can also be used with other types of predicates which the library will not transform (e.g. \mintinline{mysql}{NOT LIKE} which cannot be easily transformed to remove the use of \mintinline{mysql}{NOT}).

\begin{code}
\begin{minted}{ruby}
def transform_not(not_statement)
  # Greater
  if not_statement.value.is_a?(SQLParser::Statement::Greater)
    SQLParser::Statement::LessOrEquals.new(not_statement.value.left, not_statement.value.right)
  elsif not_statement.value.is_a?(SQLParser::Statement::GreaterOrEquals)
    SQLParser::Statement::Less.new(not_statement.value.left, not_statement.value.right)
  # Less
  elsif not_statement.value.is_a?(SQLParser::Statement::Less)
    SQLParser::Statement::GreaterOrEquals.new(not_statement.value.left, not_statement.value.right)
  elsif not_statement.value.is_a?(SQLParser::Statement::LessOrEquals)
    SQLParser::Statement::Greater.new(not_statement.value.left, not_statement.value.right)
  else
    not_statement
  end
end
\end{minted}
\caption{Transforming NOT}
\label{fig:transforming_not}
\end{code}

\subsubsection{Transform \mintinline{mysql}{>} and \mintinline{mysql}{>=} to \mintinline{mysql}{<} and \mintinline{mysql}{<=}}

Transforming \mintinline{mysql}{>} and \mintinline{mysql}{>=} to \mintinline{mysql}{<} and \mintinline{mysql}{<=} is done by simply reverting the predicate and the switching the left element of the comparison predicate with the right element of the predicate.

\begin{code}
\begin{minted}{ruby}
def transform_comparison_predicate(predicate)
  if predicate.is_a?(SQLParser::Statement::Greater)
    SQLParser::Statement::Less.new(
      predicate.right,
      predicate.left
    )
  elsif predicate.is_a?(SQLParser::Statement::GreaterOrEquals)
    SQLParser::Statement::LessOrEquals.new(
      predicate.right,
      predicate.left
    )
  else
    predicate
  end
end
\end{minted}
\caption{Transforming \mintinline{mysql}{>} and \mintinline{mysql}{>=} to \mintinline{mysql}{<} and \mintinline{mysql}{<=}}
\label{fig:transforming_great}
\end{code}

\section{Library: extracting attributes from a canonicalized query}

While sql-parser provides the AST tree for the parsed query, it does not explicitly provide the components of a query. To extract them, the library makes use of the AST and makes various transformations in order to extract the components to a desired data structure. The resulting data structure might be similar to the AST (which is true for most components), but it might also be different (for instance the FROM expression is represented as a tree in the AST, but we can more clearly represent it as an array).

These extraction and transformation process help in two important ways. First of all, it extracts the data in a format that can be easily compared and identical across similar types of expressions (for instance the structure of the WHERE component is identical to the structure of the HAVING component). In addition, the format can be defined in a way that is also easy to display on the front-end.

\subsection{Making defaults explicit}

Every \texttt{MySQL} query has certain default attributes. For instance, every \texttt{MySQL SELECT} query has a default uniqueness filter of \mintinline{mysql}{ALL}. That means while explicitly mentioning \mintinline{mysql}{ALL} will have no effect, it does not mean that it is making the query wrong. In order to accurately compare two queries, we must make the defaults explicit in both queries. The defaults will be made explicit during this extraction process.

\subsection{Format of components}

\begin{itemize}
    \item \textbf{Selected columns} are simply represented as an array of strings, where every string represents a selected column.
    \item \textbf{Order by} clause is represented represented as an array of strings, where every string represents a column.
    \item \textbf{Group} clause is represented represented as an array of strings, where every string represents a column.
    \item \textbf{Tables} clause is represented represented as an array of hashes. There are two types of hashes that can be included:
    \begin{enumerate}
        \item The first element of the array is the base table (or sub-query) of the \mintinline{mysql}{FROM} clause. The item is represented as a hash containing the following keys:
        \begin{enumerate}
            \item \mintinline{ruby}{type}: either \mintinline{ruby}{"table"} or \mintinline{ruby}{"Subquery"}
            \item \mintinline{ruby}{table}: the table name or \mintinline{ruby}{attributes} in the case of sub-queries
            \item \mintinline{ruby}{sql}: the element represented a SQL expression
        \end{enumerate}
        \item The other elements (the joined tables or joined sub-queries) of the array are represented as a hash containing the following keys:
        \begin{enumerate}
            \item \mintinline{ruby}{join_type}: the type of the join
            \item \mintinline{ruby}{table}: a hash that represents a table or sub-query. The format of the hash is the same one as the first element of the array.
            \item \mintinline{ruby}{searchcondition}: represents the join condition. Even if the search condition is similar to a Boolean component, at the moment, the join condition is represented simply as a string. The implication of this representation is that no partial grading is possible on the search condition.
            \item \mintinline{ruby}{sql}: the full SQL expression for the join (e.g. \mintinline{mysql}{LEFT JOIN table_name ON condition1 AND CONDITION 2})
        \end{enumerate}
    \end{enumerate}
    \item \textbf{Distinct filter} is represented a simple string.
    \item \textbf{Limit} clause is represented as a hash with two keys: limit and offset. If the limit is not defined then the value \texttt{inf} will be associated with it.
    \item \textbf{Where and Having} clauses are represented identically. There are two formats in which the library represents them as each format is used for a different purpose:
    \begin{enumerate}
        \item For the grading algorithm, these clauses are represented as binary trees.
        \item For the web application, these clauses are represented as trees (but not binary trees), where search conditions (e.g. \mintinline{mysql}{AND}) can have more than two children. For instance, the binary tree for expression ($ a \land b \land c$) has the following structure: 
        
\Tree[
    .$\land$
    [
        .$\land$
        [.$a$ ]
        [.$b$ ]
    ]
    [
        .$c$
    ]
]

while the tree format for the web application has the following structure

\Tree[
    .$\land$
    [
        .$a$
    ]
    [
        .$b$
    ]
    [
        .$c$
    ]
]

This format allows easier display on the front-end of the conditions.
    \end{enumerate}
\end{itemize}


\section{Library: partial grading}

\begin{code}
\begin{minted}{ruby}
def match_score(column1, column2)
  if column1 == column2
    2
  else
    table_name1, column_name1 = column1.split('.')
    table_name2, column_name2 = column2.split('.')

    if table_name1 == table_name2
      2.0 / levenshtein_distance(column_name1, column_name2)
    else
      0
    end
  end
end
\end{minted}

\caption{Match score for columns}
\end{code}

\begin{code}
\begin{minted}{ruby}
def grade
  if @student_distinct == @instructor_distinct
    1.0
  elsif @student_distinct == 'DISTINCT' && @instructor_distinct == 'DISTINCTROW'
    0.5
  elsif @student_distinct == 'DISTINCTROW' && @instructor_distinct == 'DISTINCT'
    0.5
  else
    0
  end
end
\end{minted}
\caption{Partial grading of distinct filter}
\end{code}

\section{Library: providing hints}

Currently, the hints provided are only at components level. Every wrong component has a possible hint if the match score is not 100\%. The library will check all compinents where the match score is not 100\% and select the most relevant hint. The relevance of the hint is pre-defined in the agloruthm based on the component type.

\begin{tabularx}{\textwidth}{|l|X|X|}
\hline
\textbf{Importance} & \textbf{Component} &
\textbf{Hint message}\\\hline
\endhead
1 & Tables & Are you sure you are selecting the right tables? \\\hline
2 & Columns & Check what columns you are selecting. \\\hline
3 & Group & Are you grouping by the correct columns? \\\hline
4 & Where & Looks like you are selecting the right columns, but you are not selecting only the correct rows. \\\hline
5 & Having & Looks like you are selecting the right columns, but you are not selecting only the correct rows. \\\hline
6 & Distinct filter & What about duplicates? What does the exercise say? \\\hline
7 & Limit & Are you selecting the correct number of rows? \\\hline
8 & Order by & Are you ordering the rows correctly? \\\hline

\end{tabularx}

\section{Web application: user management}
\subsection{Authentication}
Web application is implemented using the devise library. Devise is the most popular authentication library built for Ruby on Rails with over 18000 stars on GitHub and over 33 million downloads on Ruby gems. In addition to a simple login/ logout functionality, devise provides many features out of the box: recovering password, sending and handling confirmation emails, integration with OAuth providers such as Facebook login, etc. An important aspect of any authentication system is how the password are stored in the database. Devise uses the bcrypt algorithm to hash passwords. bcrypt is a password hashing function \citep{wiki:bcrypt} that is used in OpenBSD and Suse Linux and trusted by many big companies such as Dropbox \citep{dropbox:authentication}, in addition to the users of devise and other authentication libraries.

\subsection{Authorization}
To handle roles the application uses two tools: a role field on the user database, and the pundit library. pundit is a library that provides ''authorization through Object Oriented Design and pure Ruby classes'' \citep{github:pundit}. Every user has a role that is either student or admin.

Pundit defines the concept of policies which describe the authorization policy for a model. That means that every model will have an associated policy. A policy has the following attributes:

\begin{itemize}
    \item A policy is instantiated in the controller with the current user and optionally with an instance of an object.
    \item The pundit policy files define methods whose naming convention follows the Ruby on Rails controller action names described in section: \ref{ch:design:web:controller}. That means that a policy defines the following methods: \mintinline{ruby}{def index?}, \mintinline{ruby}{def show?}, \mintinline{ruby}{def create?}, \mintinline{ruby}{def new?}, \mintinline{ruby}{def update?}, \mintinline{ruby}{def edit?}, \mintinline{ruby}{def destroy?}. The method returns whether the user has access to perform the action. An example of this can be seen in listing \ref{fig:policy_challenge}, which makes it clear that only admins can crete new challenges.

\begin{code}
\begin{minted}{ruby}
class ChallengePolicy < ApplicationPolicy
  # ...
  def create?
    user.admin?
  end
  # ...
end
\end{minted}
\caption{Example policy for Challenge creation}
\label{fig:policy_challenge}
\end{code}
    \item The pundit method provides the authorize a authorize method to a Ruby on Rails controllers that automatically instantiates a policy, and automatically calls the correct method. An example of the usage of the authorize method is seen in listing \ref{fig:policy_challenge_usage} where the authorize method is called to ensure that the user has access to the challenge. If the user is not authorized, then a response with HTTP code 403 is returned to the user (HTTP code 403 means status is ''Forbidden'').
\begin{code}
\begin{minted}{ruby}
def show
  @challenge = Challenge.find_by!(id: params.require(:id))
  authorize @challenge
  # ...
end
\end{minted}
\caption{Example of policy usage}
\label{fig:policy_challenge_usage}
\end{code}
\end{itemize}

\section{Web application: front-end implementation}
Although not too much time has been spent on the web application front-end, the development of it tried to take in consideration future work that might occur on it. 

Therefore, the web application front-end is built using a modern architecture. While pages used to be powered in general mostly be HTML and CSS only, nowadays JavaScript (JS) is almost always used in all applications. However, JS in large applications is no longger used just by including a file in HTML's \mintinline{html}{<head>}. The increased popularity of JS frameworks (React, Angular, Vue, etc.) meant that most JS apps now use a build system. To prepare for this, the web application uses Webpack.  Webpack is the  module bundler endorsed by both React and Vue.

In addition to just bundling JS, Webpack also bundles other types of files. One important type of file bundled, is represented by SCSS files which are used in the web application. SCSS is, according to their creators, ''CSS with superpowers''. SCSS provides many additional features such as functions that allows us to create styles faster. For instance, the CSS styles for display the where clause as a tree with 10 levels, can be easily defined in just a few lines of code presented in listing \ref{fig:scss}, instead of defining a style for each level.

The front-end design is currently built using three tools:
\begin{enumerate}
    \item Bootstrap: an open-source frontend framework that provides CSS and JS for most common web page components.
    \item codemirror: a basic code editor that can be included in HTML page
    \item  highlight.js: a basic code highlighter (for static fields) that can be included in a HTML page.
\end{enumerate}

%TC:ignore
\begin{code}
\begin{minted}{scss}
@for $i from 0 through 10 {
  .where-clause-depth-#{$i}::before {
    content: repeat('··', $i + 1);
    margin-right: 4px;
    color: grey;
  }
}
\end{minted}
\caption{Defining tree representation of WHERE}
\label{fig:scss}
\end{code}
%TC:endignore

\section{Testing}

Testing any software is an essential step in the development process. The purpose of software testing is to validate that the software is behaving as intended \citep{lit:software_testing}. Testing can also be used to check if the requirements have been correctly implemented. As previously mentioned in the development process section (\ref{ch:reqandspec:sec:spec:subsec:dev_process}), testing has been an integral part of the project, with new tests written for all new features added.

Testing is especially important in dynamic languages like Ruby where due to the lack of types and a compile step. Ruby uses what is sometimes called \textit{duck typing} which is enforced using the duck test: ''If it walks like a duck and it quacks like a duck, then it must be a duck.'' \citep{wiki:duck_typing}. That means that Ruby only cares if an object implements a method, it does not care about the type of the object on which the method is called. While this might help developers move faster, duck typing can lead to an increased amount of errors as no type checking is done until run-time. In addition, without a proper test suite, re-factoring can become a nightmare for someone working in a dynamic programming language as he has no confidence that the changes he is making will not affect the application.

To ensure that the software is working according to the requirements and that future re-factors will be made easily, the project uses two types of testing: unit testing and integration testing.


\subsection{Unit testing}

Unit testing refers to the testing of individual units of code or groups of related units \citep{unit_testing}. The purpose of unit testing is to make sure the code meets the specifications \citep{Olan2003}. In order to unit test the two parts of the application, we are using RSpec which is a DSL testing tool for Ruby \citep{wiki:rspec}. Overall, the library and the web application have in total over 250 unit tests.

In Ruby and RSpec, tests for a class go in an associated \texttt{class\_name\_spec.rb} located in the \texttt{spec/} folder. RSpec's DSL provides multiple methods that allow most unit tests to be easy to read and understand as the resulting format of unit tests is similar to an English sentence.

\begin{code}
\begin{minted}{ruby}
context "when there is *" do
  it "returns the query containing all columns in select" do
    expect(subject.transform("SELECT * FROM table1"))
      .to eq("SELECT `table1`.`id1`, `table1`.`id2` FROM `table1`")
  end
end
\end{minted}
\caption{Example of unit test for \mintinline{mysql}{*} transform}
\label{fig:example_unit_test}
\end{code}

Both the application and the library have unit tests covering 100\% of the code. This means that every unit of code is executed at least once during the test suite. It is worth mentioning that the utility of code coverage is highly debated. Work done by \cite{msft_testing} at Microsoft Research showed that more test coverage does not necessarily result in fewer bugs. This can be associated with many factors such as the increased difficult in testing complex code. More importantly the fact that code coverage is not correlated with how users are using the app: if users spent most time using features that represent 1\% of the code, testing that 1\% is more important that achieving a high code coverage in the rest of the application. \cite{msft_testing} suggests that is more important to have better test coverage in the more complex part of the application.

To avoid the issues described by \cite{msft_testing}, both test suites try to include more tests for sensitive parts of the applications (such as canonicalization and grading process), with less tests covering non-core functionality. 

\subsection{Integration testing}

A more important type of testing is integration testing. Integration testing refers to the testing of the interaction between multiple units of the application. Integration testing makes sure that all units of an application work together according to the requirement. Integration tests are especially important in dynamic languages as classes interfaces are not checked. That means that a class will not know for sure that calling a method will succeed until run-time.

\subsubsection{Integration testing in the web application}

Integration testing in a web application has the role of checking if all MVC components. Integration testing was done using RSpec and Capybara. Capybara is a tool that simulates scenarios by directly controlling a web browser driver. That means that Capybara takes a set of instructions (such as click this button, type in this field, etc.) and executes them on actual browser. Integration testing with Capybara follows a very similar pattern to user stories. In fact, all user stories for a web application can be implemented as Capybara tests.
\begin{code}
\begin{minted}{ruby}
context "logged in as an admin" do
  context "with correct queries" do
    it "creates the challenge and displays the query" do
      visit "/challenges/new"

      fill_in "Title", with: "Challenge 1"
      fill_in "Content", with: "Challenge 1 content"
      fill_in "Sql schema", with: "CREATE TABLE t1(id integer);"
      fill_in "Sql seed", with: "INSERT INTO t1(id) VALUES (1), (2);"
      fill_in "Sql correct query", with: "SELECT * FROM t1"

      click_button "Create"

      expect(page).to have_text("Successfully created")

      expect(page).to have_text("CREATE TABLE t1(id integer);")
      expect(page).to have_text("INSERT INTO t1(id) VALUES (1), (2);")
      expect(page).to have_text("SELECT * FROM t1")
    end
  end
end
\end{minted}
\caption{Example of integration test using Capybara.}
\end{code}

\subsection{Integration testing in the library}

Integration testing in the library is basically testing of the \mintinline{ruby}{Assesor} class which internally uses all other classes. Testing the assessor is equivalent with testing the integration between the database connection and secure querying, the canonicalization process, the extraction of components, and finally the grading process. In addition to the integration tests for the assessor, other integration tests are represented by the tests for \mintinline{ruby}{QueryTransformer} which uses all transformations to transform a query, and the \mintinline{ruby}{QueryAttributeExtractor} which extract all attributes from a query.

Integration tests are defined in a \texttt{.yml} file that is then loaded and then tests are created based on that file. Listing \ref{fig:dynamically_testing} shows how integration tests for the transformer are automatically defined from a file.

\begin{code}
\begin{minted}{ruby}
yaml = YAML.load_file("spec/fixtures/transformer_integration_tests.yml")

yaml.each do |test|
  it "transform #{test['query']} to #{test['expected_result']}" do
    # Seed date
    connection.multiple_query(test["schema"])
    # Check if queries from file are correct
    connection.query(test["query"])
    connection.query(test["expected_result"])
    # Check transformation
    expect(subject.transform(test["query"])).to eq(test["expected_result"])
  end
end
\end{minted}
\caption{Dynamically defining tests based on a file}
\label{fig:dynamically_testing}
\end{code}